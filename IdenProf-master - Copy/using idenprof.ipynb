{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train']\n",
      "WARNING:tensorflow:From C:\\Users\\lizzi\\Anaconda3\\envs\\thesis2\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 112, 112, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 55, 55, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 55, 55, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 55, 55, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 55, 55, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 55, 55, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 55, 55, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 55, 55, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 55, 55, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 55, 55, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 55, 55, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 256)  0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 55, 55, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 55, 55, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 55, 55, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 55, 55, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 55, 55, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 55, 55, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 55, 55, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 55, 55, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 55, 55, 256)  0           batch_normalization_8[0][0]      \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 55, 55, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 55, 55, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 55, 55, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 55, 55, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 55, 55, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 55, 55, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 55, 55, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 55, 55, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 55, 55, 256)  0           batch_normalization_11[0][0]     \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 55, 55, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 28, 28, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 28, 28, 128)  512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 28, 28, 512)  2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 28, 28, 512)  2048        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           batch_normalization_15[0][0]     \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 28, 28, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 28, 28, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 28, 28, 512)  2048        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           batch_normalization_18[0][0]     \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 28, 28, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 28, 28, 128)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 28, 28, 512)  2048        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           batch_normalization_21[0][0]     \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 28, 28, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 28, 28, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 28, 28, 512)  2048        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           batch_normalization_24[0][0]     \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 14, 14, 256)  1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 14, 14, 256)  1024        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 14, 14, 1024) 4096        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 14, 14, 1024) 4096        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_28[0][0]     \n",
      "                                                                 batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 14, 14, 256)  1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 14, 14, 256)  1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 14, 14, 1024) 4096        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_31[0][0]     \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 14, 14, 256)  1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 14, 14, 256)  1024        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 14, 14, 1024) 4096        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_34[0][0]     \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 14, 14, 256)  1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 14, 14, 256)  1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 14, 14, 1024) 4096        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_37[0][0]     \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 14, 14, 256)  1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 14, 14, 256)  1024        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 14, 14, 1024) 4096        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_40[0][0]     \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 14, 14, 256)  1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 14, 14, 256)  1024        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 14, 14, 1024) 4096        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_43[0][0]     \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 512)    2048        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 512)    2048        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 2048)   8192        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 2048)   8192        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_47[0][0]     \n",
      "                                                                 batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 512)    2048        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 512)    2048        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 2048)   8192        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_50[0][0]     \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 512)    2048        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 512)    2048        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 2048)   8192        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_53[0][0]     \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            6147        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 3)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,593,859\n",
      "Trainable params: 23,540,739\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Using real time Data Augmentation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2700 images belonging to 3 classes.\n",
      "Found 600 images belonging to 3 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\lizzi\\Anaconda3\\envs\\thesis2\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 67s 828ms/step - loss: 1.0164 - acc: 0.6510 - val_loss: 5.6962 - val_acc: 0.4832\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.48316, saving model to C:\\Users\\lizzi\\OneDrive\\UNI\\2019\\thesis\\Machine Learning Course\\YWLAI\\IdenProf-master\\IdenProf-master\\idenprof_models\\idenprof_weight_model.001-0.4831649892859989.h5\n",
      "Epoch 2/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 635ms/step - loss: 0.6360 - acc: 0.7581 - val_loss: 0.9687 - val_acc: 0.5944\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.48316 to 0.59436, saving model to C:\\Users\\lizzi\\OneDrive\\UNI\\2019\\thesis\\Machine Learning Course\\YWLAI\\IdenProf-master\\IdenProf-master\\idenprof_models\\idenprof_weight_model.002-0.5943562717980178.h5\n",
      "Epoch 3/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.5645 - acc: 0.7876 - val_loss: 1.0111 - val_acc: 0.7354\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.59436 to 0.73545, saving model to C:\\Users\\lizzi\\OneDrive\\UNI\\2019\\thesis\\Machine Learning Course\\YWLAI\\IdenProf-master\\IdenProf-master\\idenprof_models\\idenprof_weight_model.003-0.7354497417571053.h5\n",
      "Epoch 4/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.4751 - acc: 0.8223 - val_loss: 9.3798 - val_acc: 0.3721\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.73545\n",
      "Epoch 5/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.5025 - acc: 0.7981 - val_loss: 2.3772 - val_acc: 0.5750\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.73545\n",
      "Epoch 6/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.4343 - acc: 0.8335 - val_loss: 0.5655 - val_acc: 0.7831\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.73545 to 0.78307, saving model to C:\\Users\\lizzi\\OneDrive\\UNI\\2019\\thesis\\Machine Learning Course\\YWLAI\\IdenProf-master\\IdenProf-master\\idenprof_models\\idenprof_weight_model.006-0.7830687937913118.h5\n",
      "Epoch 7/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.3783 - acc: 0.8565 - val_loss: 1.9789 - val_acc: 0.5785\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.78307\n",
      "Epoch 8/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.3837 - acc: 0.8603 - val_loss: 1.3697 - val_acc: 0.5979\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.78307\n",
      "Epoch 9/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 630ms/step - loss: 0.3185 - acc: 0.8738 - val_loss: 0.4886 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.78307 to 0.81481, saving model to C:\\Users\\lizzi\\OneDrive\\UNI\\2019\\thesis\\Machine Learning Course\\YWLAI\\IdenProf-master\\IdenProf-master\\idenprof_models\\idenprof_weight_model.009-0.8148148179684997.h5\n",
      "Epoch 10/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.3301 - acc: 0.8740 - val_loss: 2.0129 - val_acc: 0.6138\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.81481\n",
      "Epoch 11/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 52s 636ms/step - loss: 0.2697 - acc: 0.9007 - val_loss: 0.8007 - val_acc: 0.7090\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.81481\n",
      "Epoch 12/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.2389 - acc: 0.9116 - val_loss: 1.2060 - val_acc: 0.6543\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.81481\n",
      "Epoch 13/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.2380 - acc: 0.9071 - val_loss: 1.1771 - val_acc: 0.6684\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.81481\n",
      "Epoch 14/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.2333 - acc: 0.9142 - val_loss: 2.1648 - val_acc: 0.5397\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.81481\n",
      "Epoch 15/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.2135 - acc: 0.9176 - val_loss: 1.0540 - val_acc: 0.7513\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.81481\n",
      "Epoch 16/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.1802 - acc: 0.9381 - val_loss: 1.5526 - val_acc: 0.6367\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.81481\n",
      "Epoch 17/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.1862 - acc: 0.9299 - val_loss: 0.5818 - val_acc: 0.8201\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.81481 to 0.82011, saving model to C:\\Users\\lizzi\\OneDrive\\UNI\\2019\\thesis\\Machine Learning Course\\YWLAI\\IdenProf-master\\IdenProf-master\\idenprof_models\\idenprof_weight_model.017-0.8201058320898228.h5\n",
      "Epoch 18/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.1489 - acc: 0.9433 - val_loss: 0.6234 - val_acc: 0.8095\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.82011\n",
      "Epoch 19/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.1553 - acc: 0.9424 - val_loss: 0.8860 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.82011\n",
      "Epoch 20/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 631ms/step - loss: 0.2208 - acc: 0.9146 - val_loss: 8.7139 - val_acc: 0.3603\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.82011\n",
      "Epoch 21/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 630ms/step - loss: 0.1644 - acc: 0.9446 - val_loss: 0.8072 - val_acc: 0.7707\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.82011\n",
      "Epoch 22/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.1658 - acc: 0.9394 - val_loss: 0.9816 - val_acc: 0.7478\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.82011\n",
      "Epoch 23/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.1247 - acc: 0.9541 - val_loss: 0.6110 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.82011\n",
      "Epoch 24/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 630ms/step - loss: 0.0875 - acc: 0.9682 - val_loss: 1.3116 - val_acc: 0.7231\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.82011\n",
      "Epoch 25/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.1174 - acc: 0.9598 - val_loss: 1.7065 - val_acc: 0.7055\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.82011\n",
      "Epoch 26/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.1723 - acc: 0.9382 - val_loss: 1.7673 - val_acc: 0.6455\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.82011\n",
      "Epoch 27/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0775 - acc: 0.9704 - val_loss: 4.6126 - val_acc: 0.4868\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.82011\n",
      "Epoch 28/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 630ms/step - loss: 0.0931 - acc: 0.9686 - val_loss: 1.2667 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.82011\n",
      "Epoch 29/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 630ms/step - loss: 0.1046 - acc: 0.9625 - val_loss: 2.2494 - val_acc: 0.6138\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.82011\n",
      "Epoch 30/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 630ms/step - loss: 0.0834 - acc: 0.9677 - val_loss: 1.3700 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.82011\n",
      "Epoch 31/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0580 - acc: 0.9749 - val_loss: 1.1535 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.82011\n",
      "Epoch 32/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0544 - acc: 0.9824 - val_loss: 1.1018 - val_acc: 0.7372\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.82011\n",
      "Epoch 33/100\n",
      "Learning rate:  0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0772 - acc: 0.9744 - val_loss: 0.6281 - val_acc: 0.8360\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.82011 to 0.83598, saving model to C:\\Users\\lizzi\\OneDrive\\UNI\\2019\\thesis\\Machine Learning Course\\YWLAI\\IdenProf-master\\IdenProf-master\\idenprof_models\\idenprof_weight_model.033-0.8359788517472605.h5\n",
      "Epoch 34/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0637 - acc: 0.9787 - val_loss: 1.5509 - val_acc: 0.7055\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.83598\n",
      "Epoch 35/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0782 - acc: 0.9707 - val_loss: 0.9358 - val_acc: 0.7831\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.83598\n",
      "Epoch 36/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0548 - acc: 0.9790 - val_loss: 1.9051 - val_acc: 0.6861\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.83598\n",
      "Epoch 37/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0507 - acc: 0.9820 - val_loss: 0.7039 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.83598\n",
      "Epoch 38/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0748 - acc: 0.9749 - val_loss: 1.9679 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.83598\n",
      "Epoch 39/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 630ms/step - loss: 0.0819 - acc: 0.9708 - val_loss: 3.1453 - val_acc: 0.5909\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.83598\n",
      "Epoch 40/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.1605 - acc: 0.9475 - val_loss: 5.2305 - val_acc: 0.3845\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.83598\n",
      "Epoch 41/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.1009 - acc: 0.9663 - val_loss: 0.9550 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.83598\n",
      "Epoch 42/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0345 - acc: 0.9884 - val_loss: 1.0331 - val_acc: 0.7813\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.83598\n",
      "Epoch 43/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0184 - acc: 0.9928 - val_loss: 0.7236 - val_acc: 0.8254\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.83598\n",
      "Epoch 44/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0403 - acc: 0.9856 - val_loss: 1.2147 - val_acc: 0.7549\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.83598\n",
      "Epoch 45/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0291 - acc: 0.9897 - val_loss: 0.9186 - val_acc: 0.8289\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.83598\n",
      "Epoch 46/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0440 - acc: 0.9839 - val_loss: 1.2135 - val_acc: 0.7584\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.83598\n",
      "Epoch 47/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0463 - acc: 0.9847 - val_loss: 1.8367 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.83598\n",
      "Epoch 48/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0472 - acc: 0.9842 - val_loss: 0.7482 - val_acc: 0.8201\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.83598\n",
      "Epoch 49/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0341 - acc: 0.9884 - val_loss: 4.9241 - val_acc: 0.5591\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.83598\n",
      "Epoch 50/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.1217 - acc: 0.9644 - val_loss: 1.9869 - val_acc: 0.6720\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.83598\n",
      "Epoch 51/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0744 - acc: 0.9761 - val_loss: 0.9235 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.83598\n",
      "Epoch 52/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0485 - acc: 0.9877 - val_loss: 1.0005 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.83598\n",
      "Epoch 53/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0366 - acc: 0.9854 - val_loss: 0.8700 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.83598\n",
      "Epoch 54/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0222 - acc: 0.9924 - val_loss: 0.8841 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.83598\n",
      "Epoch 55/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0150 - acc: 0.9963 - val_loss: 0.9082 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.83598\n",
      "Epoch 56/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0287 - acc: 0.9879 - val_loss: 1.1754 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.83598\n",
      "Epoch 57/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0277 - acc: 0.9880 - val_loss: 0.6740 - val_acc: 0.8466\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.83598 to 0.84656, saving model to C:\\Users\\lizzi\\OneDrive\\UNI\\2019\\thesis\\Machine Learning Course\\YWLAI\\IdenProf-master\\IdenProf-master\\idenprof_models\\idenprof_weight_model.057-0.8465608541296903.h5\n",
      "Epoch 58/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 630ms/step - loss: 0.0273 - acc: 0.9895 - val_loss: 0.9561 - val_acc: 0.8199\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.84656\n",
      "Epoch 59/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0409 - acc: 0.9843 - val_loss: 1.7491 - val_acc: 0.7513\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.84656\n",
      "Epoch 60/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0356 - acc: 0.9877 - val_loss: 1.1509 - val_acc: 0.7337\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.84656\n",
      "Epoch 61/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0306 - acc: 0.9869 - val_loss: 0.8958 - val_acc: 0.8236\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.84656\n",
      "Epoch 62/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0338 - acc: 0.9891 - val_loss: 1.1193 - val_acc: 0.7496\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.84656\n",
      "Epoch 63/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0602 - acc: 0.9801 - val_loss: 1.2601 - val_acc: 0.7496\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.84656\n",
      "Epoch 64/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0645 - acc: 0.9805 - val_loss: 3.5813 - val_acc: 0.5432\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.84656\n",
      "Epoch 65/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0555 - acc: 0.9789 - val_loss: 3.3019 - val_acc: 0.6208\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.84656\n",
      "Epoch 66/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0446 - acc: 0.9892 - val_loss: 1.0248 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.84656\n",
      "Epoch 67/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0398 - acc: 0.9865 - val_loss: 1.6950 - val_acc: 0.7231\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.84656\n",
      "Epoch 68/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0090 - acc: 0.9981 - val_loss: 0.7982 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.84656 to 0.85009, saving model to C:\\Users\\lizzi\\OneDrive\\UNI\\2019\\thesis\\Machine Learning Course\\YWLAI\\IdenProf-master\\IdenProf-master\\idenprof_models\\idenprof_weight_model.068-0.8500881996104326.h5\n",
      "Epoch 69/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0168 - acc: 0.9940 - val_loss: 0.8116 - val_acc: 0.8360\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.85009\n",
      "Epoch 70/100\n",
      "Learning rate:  0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0283 - acc: 0.9903 - val_loss: 0.7196 - val_acc: 0.8095\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.85009\n",
      "Epoch 71/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0461 - acc: 0.9839 - val_loss: 1.3650 - val_acc: 0.7795\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.85009\n",
      "Epoch 72/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0489 - acc: 0.9824 - val_loss: 1.1223 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.85009\n",
      "Epoch 73/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0183 - acc: 0.9944 - val_loss: 0.7289 - val_acc: 0.8360\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.85009\n",
      "Epoch 74/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0062 - acc: 0.9989 - val_loss: 0.6445 - val_acc: 0.8483\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.85009\n",
      "Epoch 75/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0084 - acc: 0.9974 - val_loss: 0.9825 - val_acc: 0.8219\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.85009\n",
      "Epoch 76/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0120 - acc: 0.9959 - val_loss: 0.9318 - val_acc: 0.8413\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.85009\n",
      "Epoch 77/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 631ms/step - loss: 0.0443 - acc: 0.9892 - val_loss: 1.8686 - val_acc: 0.7054\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.85009\n",
      "Epoch 78/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 0.0759 - acc: 0.9793 - val_loss: 5.9202 - val_acc: 0.4392\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.85009\n",
      "Epoch 79/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0666 - acc: 0.9778 - val_loss: 1.0467 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.85009\n",
      "Epoch 80/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0307 - acc: 0.9877 - val_loss: 0.9116 - val_acc: 0.8166\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.85009\n",
      "Epoch 81/100\n",
      "Learning rate:  0.001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0137 - acc: 0.9955 - val_loss: 0.6998 - val_acc: 0.8307\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.85009\n",
      "Epoch 82/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0134 - acc: 0.9955 - val_loss: 0.7915 - val_acc: 0.8307\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.85009\n",
      "Epoch 83/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 630ms/step - loss: 0.0045 - acc: 0.9993 - val_loss: 0.8078 - val_acc: 0.8466\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.85009\n",
      "Epoch 84/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0032 - acc: 0.9996 - val_loss: 0.6958 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.85009 to 0.85714, saving model to C:\\Users\\lizzi\\OneDrive\\UNI\\2019\\thesis\\Machine Learning Course\\YWLAI\\IdenProf-master\\IdenProf-master\\idenprof_models\\idenprof_weight_model.084-0.8571428631348584.h5\n",
      "Epoch 85/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 0.8063 - val_acc: 0.8307\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.85714\n",
      "Epoch 86/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0051 - acc: 0.9981 - val_loss: 0.6836 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.85714\n",
      "Epoch 87/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.6974 - val_acc: 0.8536\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.85714\n",
      "Epoch 88/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8042 - val_acc: 0.8272\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.85714\n",
      "Epoch 89/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0032 - acc: 0.9989 - val_loss: 0.7432 - val_acc: 0.8483\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.85714\n",
      "Epoch 90/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.7403 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.85714\n",
      "Epoch 91/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8037 - val_acc: 0.8289\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.85714\n",
      "Epoch 92/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6859 - val_acc: 0.8536\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.85714\n",
      "Epoch 93/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 9.0019e-04 - acc: 1.0000 - val_loss: 0.8103 - val_acc: 0.8413\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.85714\n",
      "Epoch 94/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.7174 - val_acc: 0.8536\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.85714\n",
      "Epoch 95/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 6.5798e-04 - acc: 1.0000 - val_loss: 0.7300 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.85714\n",
      "Epoch 96/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 630ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.7529 - val_acc: 0.8434\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.85714\n",
      "Epoch 97/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 628ms/step - loss: 7.4475e-04 - acc: 1.0000 - val_loss: 0.7424 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.85714\n",
      "Epoch 98/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0014 - acc: 0.9993 - val_loss: 0.6632 - val_acc: 0.8589\n",
      "\n",
      "Epoch 00098: val_acc improved from 0.85714 to 0.85891, saving model to C:\\Users\\lizzi\\OneDrive\\UNI\\2019\\thesis\\Machine Learning Course\\YWLAI\\IdenProf-master\\IdenProf-master\\idenprof_models\\idenprof_weight_model.098-0.8589065298832282.h5\n",
      "Epoch 99/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 9.6941e-04 - acc: 1.0000 - val_loss: 0.8762 - val_acc: 0.8377\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.85891\n",
      "Epoch 100/100\n",
      "Learning rate:  0.0001\n",
      "81/81 [==============================] - 51s 629ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.7253 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.85891\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'idenprof'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-48d536d6ba96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0midenprof\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0midenprof\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'idenprof'"
     ]
    }
   ],
   "source": [
    "from idenprof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis Environment",
   "language": "python",
   "name": "thesis2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
