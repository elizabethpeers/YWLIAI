{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import keras\n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, MaxPool2D, GlobalAvgPool2D, BatchNormalization, add, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "#from __future__ import print_function\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from io import open\n",
    "from zipfile import ZipFile\n",
    "from keras.models import Model\n",
    "from tensorflow.python.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Rex the robot.ipynb',\n",
       " 'rex-images',\n",
       " 'rex-the-robot-dataset',\n",
       " 'rex_models',\n",
       " 'rex_model_class.json',\n",
       " 'Run Rex the robot.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# current working directory\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "# ----------------- The Section Responsible for Downloading the Dataset ---------------------\n",
    "\n",
    "\n",
    "SOURCE_PATH = r\"C:\\Users\\lizzi\\OneDrive\\UNI\\2019\\thesis\\Machine Learning Course\\YWLAI\\rex\"\n",
    "FILE_DIR = os.path.join(execution_path, \"rex-the-robot-dataset\")\n",
    "DATASET_DIR = os.path.join(execution_path, \"rex-images\")\n",
    "DATASET_TRAIN_DIR = os.path.join(DATASET_DIR, \"train\")\n",
    "DATASET_TEST_DIR = os.path.join(DATASET_DIR, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------- The Section Responsible for Training ResNet50 on the IdenProf dataset ---------------------\n",
    "\n",
    "# Directory in which to create models\n",
    "save_direc = os.path.join(os.getcwd(), 'rex_models')\n",
    "\n",
    "# Name of model files\n",
    "model_name = 'rex_weight_model.{epoch:03d}-{val_acc}.h5'\n",
    "\n",
    "# Create Directory if it doesn't exist\n",
    "if not os.path.isdir(save_direc):\n",
    "    os.makedirs(save_direc)\n",
    "# Join the directory with the model file\n",
    "modelpath = os.path.join(save_direc, model_name)\n",
    "\n",
    "# Checkpoint to save best model\n",
    "checkpoint = ModelCheckpoint(filepath=modelpath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             period=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function for adjusting learning rate and saving dummy file\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"\n",
    "    Learning Rate Schedule\n",
    "    \"\"\"\n",
    "    # Learning rate is scheduled to be reduced after 80, 120, 160, 180  epochs. Called  automatically  every\n",
    "    #  epoch as part  of  callbacks  during  training.\n",
    "\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 1e-4\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "\n",
    "def resnet_module(input, channel_depth, strided_pool=False):\n",
    "    residual_input = input\n",
    "    stride = 1\n",
    "\n",
    "    if (strided_pool):\n",
    "        stride = 2\n",
    "        residual_input = Conv2D(channel_depth, kernel_size=1, strides=stride, padding=\"same\",\n",
    "                                kernel_initializer=\"he_normal\")(residual_input)\n",
    "        residual_input = BatchNormalization()(residual_input)\n",
    "\n",
    "    input = Conv2D(int(channel_depth / 4), kernel_size=1, strides=stride, padding=\"same\",\n",
    "                   kernel_initializer=\"he_normal\")(input)\n",
    "    input = BatchNormalization()(input)\n",
    "    input = Activation(\"relu\")(input)\n",
    "\n",
    "    input = Conv2D(int(channel_depth / 4), kernel_size=3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\")(\n",
    "        input)\n",
    "    input = BatchNormalization()(input)\n",
    "    input = Activation(\"relu\")(input)\n",
    "\n",
    "    input = Conv2D(channel_depth, kernel_size=1, strides=1, padding=\"same\", kernel_initializer=\"he_normal\")(input)\n",
    "    input = BatchNormalization()(input)\n",
    "\n",
    "    input = add([input, residual_input])\n",
    "    input = Activation(\"relu\")(input)\n",
    "\n",
    "    return input\n",
    "\n",
    "\n",
    "def resnet_first_block_first_module(input, channel_depth):\n",
    "    residual_input = input\n",
    "    stride = 1\n",
    "\n",
    "    residual_input = Conv2D(channel_depth, kernel_size=1, strides=1, padding=\"same\", kernel_initializer=\"he_normal\")(\n",
    "        residual_input)\n",
    "    residual_input = BatchNormalization()(residual_input)\n",
    "\n",
    "    input = Conv2D(int(channel_depth / 4), kernel_size=1, strides=stride, padding=\"same\",\n",
    "                   kernel_initializer=\"he_normal\")(input)\n",
    "    input = BatchNormalization()(input)\n",
    "    input = Activation(\"relu\")(input)\n",
    "\n",
    "    input = Conv2D(int(channel_depth / 4), kernel_size=3, strides=stride, padding=\"same\",\n",
    "                   kernel_initializer=\"he_normal\")(input)\n",
    "    input = BatchNormalization()(input)\n",
    "    input = Activation(\"relu\")(input)\n",
    "\n",
    "    input = Conv2D(channel_depth, kernel_size=1, strides=stride, padding=\"same\", kernel_initializer=\"he_normal\")(input)\n",
    "    input = BatchNormalization()(input)\n",
    "\n",
    "    input = add([input, residual_input])\n",
    "    input = Activation(\"relu\")(input)\n",
    "\n",
    "    return input\n",
    "\n",
    "\n",
    "def resnet_block(input, channel_depth, num_layers, strided_pool_first=False):\n",
    "    for i in range(num_layers):\n",
    "        pool = False\n",
    "        if (i == 0 and strided_pool_first):\n",
    "            pool = True\n",
    "        input = resnet_module(input, channel_depth, strided_pool=pool)\n",
    "\n",
    "    return input\n",
    "\n",
    "\n",
    "def ResNet50(input_shape, num_classes=2):\n",
    "    input_object = Input(shape=input_shape)\n",
    "    layers = [3, 4, 6, 3]\n",
    "    channel_depths = [256, 512, 1024, 2048]\n",
    "\n",
    "    output = Conv2D(64, kernel_size=7, strides=2, padding=\"same\", kernel_initializer=\"he_normal\")(input_object)\n",
    "    output = BatchNormalization()(output)\n",
    "    output = Activation(\"relu\")(output)\n",
    "\n",
    "    output = MaxPool2D(pool_size=(3, 3), strides=(2, 2))(output)\n",
    "    output = resnet_first_block_first_module(output, channel_depths[0])\n",
    "\n",
    "    for i in range(4):\n",
    "        channel_depth = channel_depths[i]\n",
    "        num_layers = layers[i]\n",
    "\n",
    "        strided_pool_first = True\n",
    "        if (i == 0):\n",
    "            strided_pool_first = False\n",
    "            num_layers = num_layers - 1\n",
    "        output = resnet_block(output, channel_depth=channel_depth, num_layers=num_layers,\n",
    "                              strided_pool_first=strided_pool_first)\n",
    "\n",
    "    output = GlobalAvgPool2D()(output)\n",
    "    output = Dense(num_classes)(output)\n",
    "    output = Activation(\"softmax\")(output)\n",
    "\n",
    "    model = Model(inputs=input_object, outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_network():\n",
    "    #download_idenprof()\n",
    "\n",
    "    print(os.listdir(os.path.join(execution_path, \"Rex the robot\")))\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(lr=0.03, decay=1e-4)\n",
    "    batch_size = 5\n",
    "    num_classes = 2\n",
    "    epochs = 3\n",
    "\n",
    "    model = ResNet50((224, 224, 3), num_classes=num_classes)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    print(\"Using real time Data Augmentation\")\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(DATASET_TRAIN_DIR, target_size=(224, 224),\n",
    "                                                        batch_size=batch_size, class_mode=\"categorical\")\n",
    "    test_generator = test_datagen.flow_from_directory(DATASET_TEST_DIR, target_size=(224, 224), batch_size=batch_size,\n",
    "                                                      class_mode=\"categorical\")\n",
    "\n",
    "    model.fit_generator(train_generator, steps_per_epoch=int(110 / batch_size), epochs=epochs,\n",
    "                        validation_data=test_generator,\n",
    "                        validation_steps=int(40 / batch_size), callbacks=[checkpoint, lr_scheduler])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------- The Section Responsible for Inference ---------------------\n",
    "CLASS_INDEX = None\n",
    "\n",
    "MODEL_PATH = os.path.join(execution_path, \"idenprof_061-0.7933.h5\")\n",
    "JSON_PATH = os.path.join(execution_path, \"rex_model_class.json\")\n",
    "\n",
    "\n",
    "def preprocess_input(x):\n",
    "    x *= (1. / 255)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def decode_predictions(preds, top=5, model_json=\"\"):\n",
    "    global CLASS_INDEX\n",
    "\n",
    "    if CLASS_INDEX is None:\n",
    "        CLASS_INDEX = json.load(open(model_json))\n",
    "    results = []\n",
    "    for pred in preds:\n",
    "        top_indices = pred.argsort()[-top:][::-1]\n",
    "        for i in top_indices:\n",
    "            each_result = []\n",
    "            each_result.append(CLASS_INDEX[str(i)])\n",
    "            each_result.append(pred[i])\n",
    "            results.append(each_result)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_inference():\n",
    "    model = ResNet50(input_shape=(224, 224, 3), num_classes=10)\n",
    "    model.load_weights(MODEL_PATH)\n",
    "\n",
    "    picture = os.path.join(execution_path, \"Haitian-fireman.jpg\")\n",
    "\n",
    "    image_to_predict = image.load_img(picture, target_size=(\n",
    "        224, 224))\n",
    "    image_to_predict = image.img_to_array(image_to_predict, data_format=\"channels_last\")\n",
    "    image_to_predict = np.expand_dims(image_to_predict, axis=0)\n",
    "\n",
    "    image_to_predict = preprocess_input(image_to_predict)\n",
    "\n",
    "    prediction = model.predict(x=image_to_predict, steps=1)\n",
    "\n",
    "    predictiondata = decode_predictions(prediction, top=int(5), model_json=JSON_PATH)\n",
    "\n",
    "    for result in predictiondata:\n",
    "        print(str(result[0]), \" : \", str(result[1] * 100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\lizzi\\\\OneDrive\\\\UNI\\\\2019\\\\thesis\\\\Machine Learning Course\\\\YWLAI\\\\rex\\\\Rex the robot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f57110a41dce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# run_inference()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-99c7c179e451>\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m()\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;31m#download_idenprof()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecution_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Rex the robot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.03\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\lizzi\\\\OneDrive\\\\UNI\\\\2019\\\\thesis\\\\Machine Learning Course\\\\YWLAI\\\\rex\\\\Rex the robot'"
     ]
    }
   ],
   "source": [
    "# run_inference()\n",
    "train_network()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis Environment",
   "language": "python",
   "name": "thesis2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
